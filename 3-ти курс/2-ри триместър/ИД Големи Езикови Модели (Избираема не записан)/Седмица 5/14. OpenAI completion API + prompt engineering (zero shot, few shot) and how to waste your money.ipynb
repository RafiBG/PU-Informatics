{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyN3/7NMJDWM9xwUCrxnuUUS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# OpenAI completion API + Prompt Engineering (zero shot, few shot) and how to waste your money"],"metadata":{"id":"yVaGtSpLrhpw"}},{"cell_type":"markdown","source":[" **OpenAI Completion API** е уеб базиран интерфейс, който позволява на разработчиците да взаимодействат с езикови модели, предоставени от OpenAI. Чрез изпращане на prompt (част от текст), API генерира и връща завършване - допълнителен текст, който продължава или отговаря на входа. Този API е проектиран да поддържа голямо разнообразие от задачи за обработка на естествен език, като например генериране на текст, обобщаване, превод и други. Разработчиците могат да персонализират генерирането чрез коригиране на параметри като температура (която контролира произволността), максимален брой токени и други, за да постигнат желания стил и качество на изхода.\n","\n"," **Prompt Engineering** е процес на проектиране и усъвършенстване на промптове за въвеждане, за да се извлече ефективно желаното поведение от езиковите модели. Тази практика включва внимателно избиране на формулировка, контекст и понякога примери, които да насочват модела към генериране на подходящи и точни резултати. Тъй като езиковите модели работят въз основа на модели, научени по време на обучението, структурата и яснотата на промпта могат значително да повлияят на качеството на резултатите. Ефективният prompt engineering е особено важно, когато задачата е сложна или когато се изисква висока степен на специфичност в отговора."],"metadata":{"id":"65etBw7wv7ID"}},{"cell_type":"markdown","source":["# System Prompt & User Prompt"],"metadata":{"id":"csagJEGULRcF"}},{"cell_type":"markdown","source":["# Какво е System Prompt?\n","\n","System Prompts служат като основни инструкции, които диктуват поведението на AI. Те установяват framework за това как AI ще взаимодейства и ще реагира, подобно на длъжностна характеристика за служител. Тези промптове определят ролята на AI, неговата област на експертиза и общия тон, който трябва да приеме.\n","\n","Ключовите елементи на системните промптове включват:\n","\n"," * Behavioral Framing (поведенческо): Определяне на ролята, личността или експертизата на AI.\n"," * Настройка на ограничения: Установяване на ограничения или правила за отговорите на AI.\n"," * Предоставяне на контекст: Предоставяне на основна информация или контекст на ситуацията.\n"," * Етични насоки: Включване на етични насоки или съпоставяне на ценностите.\n","\n","Системните промптове обикновено се дефинират от разработчиците и остават последователни при множество потребителски взаимодействия, освен ако не са променени умишлено.\n","\n","Важно е да се отбележи, че различните модели могат да реагират на системни промптове по уникален начин. Това означава, че се отдава по-голямо значение на това как потребителят инструктира модела."],"metadata":{"id":"q8PmTHiVLZdz"}},{"cell_type":"markdown","source":["# Какво е User Prompt?\n","\n","User Prompt са специфичните инструкции или въпроси, които потребителят предоставя на система с изкуствен интелект, за да предизвика желания отговор. Тези промптове са динамични и варират при всяко взаимодействие, отразявайки непосредствените нужди и цели на потребителя. Те могат да варират от прости искания за информация до сложни инструкции за генериране на творческо съдържание или кодоране.\n","\n","Потребителските промптове могат да бъдат много неща:\n","\n"," * Промптове за генериране: Те инструктират AI да генерира ново съдържание, като текст, изображения или код. Например, потребител може да поиска от AI да напише кратка история или да генерира кодов фрагмент за конкретна функция.\n"," * Разговор: Те започват или продължават разговор с AI, което позволява по-интерактивен и динамичен обмен. Например потребител може да зададе въпрос на AI и след това да последва изясняващи въпроси или искания за повече информация.\n"," * Класификация: Тези промптове изискват от AI да категоризира входните данни въз основа на предварително дефинирани етикети или категории. Например потребител може да поиска от AI да класифицира рецензията на продукта като положителна или отрицателна.\n"," * Извличане: Изискват от AI да извлече специфична информация от даден текст или набор от данни. Например потребител може да поиска от AI да извлече всички имена на хора, споменати в новинарска статия и т.н."],"metadata":{"id":"vsuT_h9ANRoF"}},{"cell_type":"markdown","source":["# Примери за системни и потребителски промптове\n","\n","**Prompt Type**\t| **Example**\n","\n","**System Prompt**:\t\"You are a helpful and informative AI assistant that specializes in technology.\"\n","\n","**System Prompt**:\t\"You are an experienced customer service representative. Always maintain a polite and professional tone.\"\n","\n","**User Prompt**:\t  \"Write a 500-word essay on the impact of social media on modern society, including the benefits and drawbacks.\"\n","\n","**User Prompt**:\t  \"Generate a list of SEO keywords for a new restaurant in New York City that specializes in Italian food.\"\n","\n","**User prompt**:    \"You're helpful, friendly assistant who help with tasks.\""],"metadata":{"id":"us727_tJOVTl"}},{"cell_type":"markdown","source":["# OpenAPI\n","\n","OpenAI API предоставя прост интерфейс към най-съвременните AI модели за обработка на естествен език, генериране на изображения, семантично търсене и разпознаване на реч.\n","\n","Как се генерира текст от промпт.\n","\n","OpenAI предоставя прости API за използване на голям езиков модел за генериране на текст от промпт, както се използва ChatGPT. Тези модели са обучени на огромни количества данни, за да разберат мултимедийни входове и инструкции на естествен език. От тези промптове моделите могат да генерират почти всякакъв вид текстов отговор, като код, математически уравнения, структурирани JSON данни или човешка проза.\n","\n","### Настройване на средатa:\n","\n"," Създаване или влизане в OpenAI акаунта:\n"," [Уебсайта с документация за API на OpenAI](https://platform.openai.com/settings/organization/api-keys). Тази стъпка е от решаващо значение, тъй като дава достъп до API ключовете, необходими за удостоверяване."],"metadata":{"id":"r36DIg44-BS9"}},{"cell_type":"markdown","source":["### Генериране на API ключ:\n","\n"," * Навигиране до секцията с API ключове в таблото за управление на акаунта в OpenAI.\n"," * Създаване на нов API ключ. Не забравяйте незабавно да копирате този ключ, тъй като той няма да се вижда отново, след като страницата се напусне."],"metadata":{"id":"Dx7v1A5oBxP9"}},{"cell_type":"markdown","source":["# Zero-Shot"],"metadata":{"id":"fMB4qyo32KjP"}},{"cell_type":"markdown","source":["Обучението с **Zero-Shot** се отнася до сценарий, при който езиков модел е накаран да изпълни задача, без да е видял никакви примери или да получи фина настройка (fine-tun), специфична за задачата, по време на промпта. Моделът разчита единствено на общите знания, които е придобил по време на обучението си, за да разбере и отговори на задачата. Тази способност е особено полезна, когато е непрактично да се предоставят примери или когато се очаква моделът да се обобщи за изцяло нови задачи или области въз основа на своите предварително съществуващи знания."],"metadata":{"id":"IxMrsB_T2Hqc"}},{"cell_type":"markdown","source":["В този пример промпта изисква от модела да извърши анализ на настроението, без да предоставя никакви примери:"],"metadata":{"id":"vTiaICbj2Yr9"}},{"cell_type":"code","source":["!pip install openai==0.28"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZaaHoOI_J-JP","executionInfo":{"status":"ok","timestamp":1747393842581,"user_tz":-180,"elapsed":8415,"user":{"displayName":"Детелинка Трифонова","userId":"00466711936934599379"}},"outputId":"172d30fa-7833-4c50-fef2-5deabc613a77"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting openai==0.28\n","  Downloading openai-0.28.0-py3-none-any.whl.metadata (13 kB)\n","Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.11/dist-packages (from openai==0.28) (2.32.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai==0.28) (4.67.1)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from openai==0.28) (3.11.15)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (2025.4.26)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (1.6.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (6.4.3)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (0.3.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (1.20.0)\n","Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: openai\n","  Attempting uninstall: openai\n","    Found existing installation: openai 1.78.1\n","    Uninstalling openai-1.78.1:\n","      Successfully uninstalled openai-1.78.1\n","Successfully installed openai-0.28.0\n"]}]},{"cell_type":"code","source":["import openai\n","import os\n","\n","os.environ[\"OPENAI_API_KEY\"] = \"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\"\n","openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n","\n","prompt = \"Determine the sentiment of the following sentence: 'The movie was thrilling and suspenseful.'\"\n","\n","'''response = openai.Completion.create( # Call Completion API\n","    engine=\"text-davinci-003\", # Параметърът на engine указва коя версия на езиковия модел да се използва за генериране на завършването\n","    prompt=prompt, # Prompt е първоначалният текст, който се предоставя на API. Той задава контекста, инструкциите или задачата, която искаме да изпълнява езиковият модел.\n","                                     # Служи като отправна точка за модела за генериране на отговор\n","    max_tokens=10, # Определя максималния брой токени, които API може да генерира при завършване.\n","                                     # Представлява дума или част от дума (например пунктуация или поддума)\n","    temperature=0.5 # Temperature контролира произволността или креативността на изхода, генериран от модела.\n","                                     # Влияе върху начина, по който моделът избира следващия токен в своя отговор\n",")'''\n","\n","response = openai.ChatCompletion.create(\n","    model=\"gpt-4o-mini\",\n","    messages=[{\"role\": \"user\", \"content\": prompt}],\n","    max_tokens=10,\n","    temperature=0.5 # 0.5- == accurate; 1+ = creative\n",")\n","\n","#print(\"Zero-shot result:\", response.choices[0].text.strip())\n","\n","print(\"Zero-shot result:\", response[\"choices\"][0][\"message\"][\"content\"].strip())"],"metadata":{"id":"fJcDK8xJ2NMB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1747393852056,"user_tz":-180,"elapsed":1024,"user":{"displayName":"Детелинка Трифонова","userId":"00466711936934599379"}},"outputId":"40fb4ee5-2e54-4422-d665-ca56d5261e5f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Zero-shot result: The sentiment of the sentence \"The movie was thrilling\n"]}]},{"cell_type":"markdown","source":["# Few-Shot"],"metadata":{"id":"J7J4By2M2N5G"}},{"cell_type":"markdown","source":[" **Few-Shot** обучение е подобно на zero-shot, но в този случай промпта включва малък брой примери, които илюстрират настоящата задача. Тези примери помагат на модела да разбере желаното входно-изходно картографиране и да създаде по-точни или контекстуално релевантни завършвания. Чрез предоставяне само на няколко примера – често един до няколко – моделът може да изведе по-добре изискванията на задачата и да подобри своята производителност без необходимост от обширно обучение за конкретна задача."],"metadata":{"id":"hmYMKy9P2Qh5"}},{"cell_type":"code","source":["import openai\n","import os\n","\n","os.environ[\"OPENAI_API_KEY\"] = \"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\"\n","openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n","\n","'''prompt = (\n","    \"Examples of sentiment analysis:\\n\"\n","    \"- Example 1: 'I absolutely loved the concert.' → Sentiment: Positive\\n\"\n","    \"- Example 2: 'The food was terrible and the service was slow.' → Sentiment: Negative\\n\\n\"\n","    \"Now, determine the sentiment of the following sentence: 'The experience was okay, not too exciting but not disappointing either.'\"\n",")\n","\n","response = openai.Completion.create(\n","    engine=\"gpt-3.5-turbo\", # text-davinci-003\n","    prompt=prompt,\n","    max_tokens=10,\n","    temperature=0.5\n",")'''\n","\n","messages = [\n","    {\"role\": \"system\", \"content\": \"You are a helpful assistant that performs sentiment analysis.\"},\n","    {\"role\": \"user\", \"content\": (\n","        \"Examples of sentiment analysis:\\n\"\n","        \"- Example 1: 'I absolutely loved the concert.' → Sentiment: Positive\\n\"\n","        \"- Example 2: 'The food was terrible and the service was slow.' → Sentiment: Negative\\n\\n\"\n","        \"Now, determine the sentiment of the following sentence: 'The experience was okay, was too exciting but not disappointing either.'\"\n","    )}\n","]\n","\n","response = openai.ChatCompletion.create(\n","    model=\"gpt-4o-mini\",\n","    messages=messages,\n","    max_tokens=10,\n","    temperature=0.5\n",")\n","\n","print(\"Few-shot result:\", response[\"choices\"][0][\"message\"][\"content\"].strip())"],"metadata":{"id":"GAqBEmYo2SR6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1747393855662,"user_tz":-180,"elapsed":634,"user":{"displayName":"Детелинка Трифонова","userId":"00466711936934599379"}},"outputId":"71a2501f-fc2b-4224-f2c7-2f0ada7617bc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Few-shot result: Sentiment: Neutral\n"]}]},{"cell_type":"markdown","source":["Лоши практики:\n","\n"," * Може умишлено са изберани прекалено сложни, неоптимизирани подкани.\n"," * Можете да се използват параметри с висока цена и скъпи версии на модели за прости задачи.\n"," * Може да се пренебрегне най-добрите практики като бързо прецизиране и наблюдение на използването, което води до прекомерни, неефективни извиквания на API."],"metadata":{"id":"ZNaPBnCX0ont"}},{"cell_type":"markdown","source":["------------------"],"metadata":{"id":"1FSwXGLKonxi"}},{"cell_type":"code","source":["!pip install --upgrade openai"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pxz19NEFmqwH","executionInfo":{"status":"ok","timestamp":1747399530608,"user_tz":-180,"elapsed":11681,"user":{"displayName":"Детелинка Трифонова","userId":"00466711936934599379"}},"outputId":"f3c5fdfc-c431-4b3a-999f-271bd484b27e"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.78.1)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n","Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n","Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.4)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n","Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n","Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.13.2)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n"]}]},{"cell_type":"code","source":["!pip show openai"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QJn8iTlKzGTy","executionInfo":{"status":"ok","timestamp":1747394767051,"user_tz":-180,"elapsed":3134,"user":{"displayName":"Детелинка Трифонова","userId":"00466711936934599379"}},"outputId":"23e5f7e5-3f7f-447d-d499-032803022c47"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Name: openai\n","Version: 1.78.1\n","Summary: The official Python library for the openai API\n","Home-page: https://github.com/openai/openai-python\n","Author: \n","Author-email: OpenAI <support@openai.com>\n","License: Apache-2.0\n","Location: /usr/local/lib/python3.11/dist-packages\n","Requires: anyio, distro, httpx, jiter, pydantic, sniffio, tqdm, typing-extensions\n","Required-by: \n"]}]},{"cell_type":"code","source":["import os\n","\n","from openai import OpenAI\n","\n","''' #OpenAI api key\n","    #api_key=\"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\"\n","\n","    #deepinfra.com API url and api key\n","    base_url=\"https://api.deepinfra.com/v1/openai\",\n","    api_key=\"Juz2en9YSRQ9BgJk9BVIz3k2y2o3eyL6\", '''\n","\n","#os.environ[\"DEEPINFRA_API_KEY\"] = \"7UoX2yh7PCxFZgmXWhoIj6vN3YbwYZh9\"\n","\n","#api_key=[\"OPENAI_API_KEY\"] = \"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\"\n","\n","client = OpenAI(\n","    #api_key=\"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\"\n","    base_url=\"https://api.deepinfra.com/v1/openai\",\n","    api_key=\"Juz2en9YSRQ9BgJk9BVIz3k2y2o3eyL6\",\n",")\n","\n","#model = \"gpt-4o-mini\"\n","#model = \"meta-llama/Meta-Llama-3.1-405B-Instruct\"\n","#model = \"meta-llama/Llama-3.3-70B-Instruct\"\n","model = \"deepseek-ai/DeepSeek-R1\"\n","#model = \"deepseek-ai/DeepSeek-V3\"\n","\n","#system_msg = \"You are really unpolite and sarcastic.\"\n","#system_msg = \"You are super serious and conservative.\" # let's talk about music, bro. My favourite band is Metallica, what's yours?\n","system_msg = \"You are a helpful assistant \\\n","that answers programming \\\n","questions in the style of a \\\n","southern belle from the \\\n","southeast United States.\"\n","#system_msg = \"Write a haiku about programming.\"\n","\n","messages = [{\"role\": \"system\", \"content\": system_msg}]\n","\n","def chat():\n","    while True:\n","        user_msg = input(\"User: \")\n","        if user_msg.strip().lower() in [\"exit\", \"quit\", \"stop\"]:\n","            print(\"Chatbot session ended.\")\n","            break\n","\n","        messages.append({\"role\": \"user\", \"content\": user_msg})\n","\n","        print()\n","        print(\"===================\")\n","        print(messages)\n","        print(\"===================\")\n","        print()\n","\n","        completion = client.chat.completions.create(\n","            model=model,\n","            temperature=0.5,\n","            messages=messages\n","        )\n","\n","        answer = completion.choices[0].message.content\n","        answer = answer.replace(\".\", \".\\n\")\n","        messages.append({\"role\": \"assistant\", \"content\": answer})\n","\n","        print(\"\\nAssistant:\", answer, \"\\n\")\n","\n","chat()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KvBLuvRxmr0E","executionInfo":{"status":"ok","timestamp":1747399568662,"user_tz":-180,"elapsed":16789,"user":{"displayName":"Детелинка Трифонова","userId":"00466711936934599379"}},"outputId":"8877c166-b4fe-4ec3-bb0d-dfbdd6aa9f06"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["User: fgg\n","\n","===================\n","[{'role': 'system', 'content': 'You are a helpful assistant that answers programming questions in the style of a southern belle from the southeast United States.'}, {'role': 'user', 'content': 'fgg'}]\n","===================\n","\n","\n","Assistant: <think>\n","Okay, the user typed \"fgg\".\n"," Hmm, that doesn't look like a typical programming question.\n"," Maybe it's a typo? Let me think.\n"," Could they have meant \"fg\" as in foreground in a Unix context? Or perhaps \"FGG\" as an acronym for something else?\n","\n","Wait, maybe they're referring to a programming term or a specific function.\n"," Let me check common abbreviations.\n"," \"FGG\" isn't ringing a bell immediately.\n"," Maybe it's part of a larger term they forgot to finish.\n"," Or maybe it's a typo for \"fg\" which is a shell command to bring a job to the foreground.\n"," \n","\n","Alternatively, could it be related to a framework, library, or a specific language feature? Let me consider different possibilities.\n"," If they're asking about \"fg\" in the context of job control in a shell, I can explain that.\n"," But if it's a typo for something else, like \"function generator\" or \"FGG\" as an abbreviation in a specific domain, I might need more context.\n"," \n","\n","Since the user hasn't provided more details, I should ask for clarification.\n"," It's better to be sure what they need help with rather than guessing and providing irrelevant information.\n"," Southern belle style requires being polite and helpful, so I'll phrase the response in a friendly manner, inviting them to clarify their question.\n","\n","</think>\n","\n","Why, bless your heart, darlin', it seems like there might be a little typo or shorthand there! Could you kindly clarify what you mean by \"fgg\"? Are we talkin' 'bout a programming concept, a snippet of code, or somethin' else entirely? I'm all ears, sugar—just want to make sure I give you the help you need! 💖 \n","\n","User: stop\n","Chatbot session ended.\n"]}]},{"cell_type":"markdown","source":["[DeepInfra Chat](https://deepinfra.com/)"],"metadata":{"id":"DGwmJ7qRo6Lj"}}]}